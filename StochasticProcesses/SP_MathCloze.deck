# Number; Cloze phrase; Reference
# Sets
SP_CH2_01; The {{c1::sum}} or {{c1::union}} of two sets \(A\) and \(B\) is a set whose elements are all elements of {{c2::\(A\) or \(B\) or both}}. This is written {{c1::\(A + B\)}} or {{c1::\(A \cup B\)}}; pg 17
SP_CH2_02; The {{c1::product}} or {{c1::intersection}} of two sets \(A\) and \(B\) is a set whose elements are all elements of {{c2::\(A\) and \(B\)}}. This is written {{c1::\(AB\)}} or {{c1::\(A \cap B\)}}; pg 17
SP_CH2_03; \(A(B \cup C ) = \) {{c1::\(AB \cup AC\)}}; pg 17
SP_CH2_04; Two sets \(A\) and \(B\) are said to be {{c1::mutually exclusive}} or {{c1::disjoint}} if they have {{c2::no common elements}}, that is, if {{c2::\(AB = \varnothing\)}}; pg 18
SP_CH2_05; A {{c1::partition}} of a set \(S\) is a collection of {{c2::mutually exclusive}} subsets of \(S\) whose union {{c2::equals \(S\)}}; pg 18
SP_CH2_06; The {{c1::complement}} \(\bar{A}\) of a set \(A\) is the set consisting of {{c2::all elements}} in \(S\) that {{c2::are not in}} \(A\);
SP_CH2_07; De Morgan's Law <br> {{c1::\(\overline{A \cup B}\)}} \(=\) {{c2::\(\bar{A} \bar{B}\)}}; pg 18
SP_CH2_08; De Morgan's Law <br> {{c1::\(\overline{AB}\)}} \(=\) {{c2::\(\bar{A} \cup \bar{B}\)}}; pg 18
SP_CH2_09; If \(A\) is a set with \(N\) elements, the cardinality of \(A\) is \(|A| = \) {{c1::\(N\)}}; Class notes
SP_CH2_10; If \(A\) is a set with \(N\) elements, there are {{c1::\(2^N\)}} subsets in \(A\); Class notes
#Probability
SP_CH2_11; A {{c1::probability space}} is the triple \( (S \text{ or } \Omega, \mathcal{E}, P) \), where <br> \(S\) or \(\Omega\) is the {{c2::sample space}} or set of {{c2::all possible experimental outcomes}} <br> \(\mathcal{E}\) is the {{c2::event space}} <br> \(P\) is the {{c2::probability measure}} \(P\colon\) {{c2::\(\mathcal{E} \to [0, 1] \)}}; pg 19
SP_CH2_12; For the probability measure \(P\) and the event \(A \in \mathcal{E}\) <br> \(P(A) \geq \) {{c1::\(0\)}}; Axiom I, pg 20
SP_CH2_13; For the probability measure \(P\) <br> \(P(\Omega) = \) {{c1::\(1\)}}; Axiom II, pg 20
SP_CH2_14; For the probability measure \(P\) and the events \(A, B \in \mathcal{E}\) <br> if \(AB = \varnothing \) then \(P(A \cup B) = \) {{c1::\(P(A) + P(B)\)}}; Axiom III, pg 20
SP_CH2_15; For any \(A,\:B \in \mathcal{E}\), <br> \(P(A \cup B) = \) {{c1::\(P(A) + P(B) - P(AB) \)}} \(\leq\) {{c1::\(P(A) + P(B) \)}}; Equation 2-13, pg 20
SP_CH2_16; The {{c1::conditional probability}} of an event \(A\) given the occurance of another event \(M\) is denoted {{c2::\(P(A|M)\)}}; Equation 2-33, pg 28
SP_CH2_17; Conditional probability <br> \(P(A|M) = \) {{c1::\(\frac{P(AM)} {P(M)} \) }}; Equation 2-33, pg 28
SP_CH2_18; \(A \cup B \) = {{c1::\(A \cup \bar{A} B\)}} <br> (Set trick for proofs); 
SP_CH2_19; \( B \) = {{c1::\(SB\)}} = {{c1::\( (A \cup \bar{A}) B\) }} <br> (Set trick for proofs);
SP_CH2_20; If \(\{A_1, \dots, A_n\}\) is a partition of \(S\) and \(B\) is an arbitrary event, then <br> \(P(B) = \) {{c1::\(P(B|A_1)P(A_1) + \dots + P(B|A_n)P(A_n) \)}}; Total probability theorem, pg 32
SP_CH2_21; Baye's Rule <br> \(P(A | B) = \) {{c1::\(\frac{P(B | A) P(A)} {P(B)}\) }}; 
SP_CH2_22; Two events \(A\) and \(B\) are {{c1::independent}} if \(P(AB) = \) {{c2:: \(P(A)P(B)\) }}; Equation 2-50, pg 35
# Chapter 4
SP_CH4_01; A {{c1::random variable}} \(\mathbf{x}\) is a process of assigning a number \(\mathbf{x}(\zeta)\) to every outcome \(\zeta\); Definition, pg 74
SP_CH4_02; The {{c1::cumulative distribution function}} of the random variable \(\mathbf{x}\) is the function \(F_{\mathbf{x} }(x) = \) {{c2::\(P\{ \zeta | \mathbf{x}(\zeta) \leq x \} \) }}; Equation 4-1, pg 75
SP_CH4_03; The {{c1::\(u\) percentile}} of a random variable \(\mathbf{x}\) is the smallest number \(x_u\) such that \(u = \) {{c2::\(P\{ \mathbf{x} \leq x_u \} = F_{\mathbf{x} }(x_u) \)}}; Equation 4-2, pg 77
SP_CH4_04; \(F(\infty) = \) {{c1::\(1\)}}; Property 1, pg 78
SP_CH4_05; \(F(-\infty) = \) {{c1::\(0\)}}; Property 1, pg 78
SP_CH4_06; If \(x_1 < x_2\) then \(F(x_1)\) {{c1::\(\leq\)}} \(F(x_2)\); Property 2, pg 78
SP_CH4_07; If \(F(x_0) = 0\) then \(F(x) = \) {{c1::\(0\)}} for every {{c1::\(x \leq x_0\)}}; Property 3, pg 78
SP_CH4_08; \(P\{\mathbf{x} > x \} = \) {{c1::\(1 - F(x)\)}}; Property 4, pg 79
SP_CH4_09; The function \(F(x)\) is continuous from the {{c1::right}}, ie<br> \(F(x^+) = \) {{c1::\(F(x)\)}}; Property 5, pg 79
SP_CH4_10; \(P\{ x_1 < \mathbf{x} \leq x_2 \} = \) {{c1::\(F(x_2) - F(x_1)\)}}; Property 6, pg 79
SP_CH4_11; \(P\{\mathbf{x} = x \} = \) {{c1::\(F(x) - F(x^-)\)}}; Property 7, pg 79
SP_CH4_12; \(P\{ x_1 \leq \mathbf{x} \leq x_2 \} = \) {{c1::\(F(x_2) - F(x_1^-)\)}}; Property 8, pg 79
SP_CH4_13; The {{c1::derivative}} of the probability distribution function \(F_{\mathbf{x} }(x)\) is called the {{c2::probability density function}} \(f_{\mathbf{x} } (x)\).; Equation 4-13, pg 81
SP_CH4_14; \(f_{\mathbf{x} } (x) =\) {{c1::\(\frac{d F_{\mathbf{x} }(x) } { dx} \)}}; Equation 4-13, pg 81
SP_CH4_15; \(F_{\mathbf{x} } (x) =\) {{c1::\( \int_{-\infty}^{x} f_{\mathbf{x} }(u) } du \)}}; Equation 4-13, pg 81
#Chapter 5
SP_CH5_01; The {{c1::expected value}} or {{c1::mean}} of a random variable \(\mathbf(x)\) is by definition the integral {{c1::\[E[\mathbf{x}] =\) }} {{c2:: \( \int_{-\infty}^{\infty} x f(x) dx\]}}; Equation 5-44, pg 140
SP_CH5_02; \(E[a\mathbf{x} + b] =\) {{c1::\(aE[\mathbf{x}] + b\)}}; 
SP_CH5_03; \(E[g(\mathbf{x})] = \){{c1::\( \int_{-\infty}^{\infty} g(x) f_{\mathbf{x} }(x) dx\) }};
SP_CH5_04; Variance <br> {{c1::\(E[(\mathbf{x} - \mu)^2] \)}} \(=\) {{c2::\(E[\mathbf{x}^2] -  (E[\mathbf{x}])^2 \) }}; Equations 5-59 and 5-61, pg 144-45,
SP_CH5_06; {{c1::Univariate normal}} density function for \(\mathbf{x} \sim \) {{c1::\(N(\mu, \sigma^2) \)}}. <br> \(f_{\mathbf{x} } (x) = \) {{c2:: \(\frac{1}{\sqrt{2 \pi \sigma^2} } e^{-(x - \mu)^2 / 2 \sigma^2} \)}}; Table 5-2, pg 162
SP_CH5_07; {{c1::Uniform}} density function for \(\mathbf{x} \sim \) {{c1::\( U(a,b)\)}}. <br> \(f_{\mathbf{x} } (x) = \) {{c2::\( \frac{1}{b-a} \)}}; Table 5-2, pg 162
SP_CH5_08; {{c1::Mean}} for \(\mathbf{x} \sim \) {{c1::\( U(a,b)\)}}. <br> {{c2::\( \frac{a+b}{2} \)}}; Table 5-2, pg 162
SP_CH5_09; {{c1::Variance}} for \(\mathbf{x} \sim \) {{c1::\( U(a,b)\)}}. <br> {{c2::\( \frac{(b-a)^2}{12} \)}}; Table 5-2, pg 162
# Chapter 6
SP_CH6_01; If \(\mathbf{x}\) and \(\mathbf{y}\) are independent, then \(f_{\mathbf{x}\mathbf{y} } (x, y) = {{c1:: f_{\mathbf{x} } (x) f_{\mathbf{y} } (y) }}\); Equation 6-42, pg 182
SP_CH6_02; Two random variables \(\mathbf{x}\) and \(\mathbf{y}\) are {{c1::independent}} if the events \(\{\mathbf{x} \in A\}\) and \(\{\mathbf{y} \in B\}\) are {{c1::independent}}, that is, if <br> \(P\{\mathbf{x} \in A, \mathbf{y} \in B\} = {{c2::P\{\mathbf{x} \in A\} P\{\mathbf{y} \in B\} }}\).; Equation 6-18, pg 173
SP_CH6_03; If the random variables \(\mathbf{x}\) and \(\mathbf{y}\) are independent, then<br>\(F(x, y) = {{c1:: F_{\mathbf{x} }(x) F_{\mathbf{y} }(y)}}\) <br> and <br> \(f(x, y) = {{c1:: f_{\mathbf{x} }(x) f_{\mathbf{y} }(y)}}\); Equation 6-19 and 6-20, pg 173
SP_CH6_04; The {{c1::joint}} distribution \(F_{\mathbf{x} \mathbf{y} } (x, y)\) or \(F(x, y)\) of two random variables \(\mathbf{x}\) and \(\mathbf{y}\) is the probability of the event<br>\({{c1::\{\mathbf{x} \leq x, \mathbf{y} \leq y\} }}\); Pg 169
SP_CH6_05; The function \(F_{\mathbf{x} \mathbf{y} } (x, y)\) is such that<br>\(F_{\mathbf{x} \mathbf{y} } (-\infty, y) = {{c1::0}}\), \(F_{\mathbf{x} \mathbf{y} } (x, -\infty) = {{c1::0}}\), and \(F_{\mathbf{x} \mathbf{y} } (\infty, \infty) = {{c1::1}}\); Property 1, pg 170
SP_CH6_06; If the random variables \(\mathbf{x}\) and \(\mathbf{y}\) are {{c1::independent}}, then the random variables \(\mathbf{z} = g(\mathbf{x})\) and \(\mathbf{w} = h(\mathbf{y})\) are {{c1::independent}}.; Theorem 6-1, pg 174
SP_CH6_07; Given the random variables \(\mathbf{x}\), \(\mathbf{y}\), \(\mathbf{z} = g(\mathbf{x}, \mathbf{y})\), and the density \(f_{\mathbf{x}\mathbf{y} }\), the distribution of \(\mathbf{z}\) is<br> \(F_{\mathbf{z} }(z) = P\{ \) {{c1::\(g(\mathbf{x}, \mathbf{y}) \leq z\)}} \( \} = \iint_{x, y \in D_z} \) {{c1:: \(f_{\mathbf{x}\mathbf{y} }(x, y) dx dy \) }}<br>where \(D_z\) is the region where {{c1::\(g(\mathbf{x}, \mathbf{y}) \leq z\)}}; Equation 6-37, pg 180
SP_CH6_08; If \(z = g(x, y)\) and \(w = h(x, y)\) are {{c1::continuous}} and {{c1::differentiable}}, it is possible to obtain the density \(f_{\mathbf{z}\mathbf{w} } (z, w) \) directly from the density \(f_{\mathbf{x}\mathbf{y} } (x, y) \); Pg 199, also Section6.3 slides number 16
SP_CH6_09; Let \(\mathbf{z} = g(\mathbf{x}, \mathbf{y})\) and \(\mathbf{w} = h(\mathbf{x}, \mathbf{y})\). Now suppose for a given \(z\) and \(w\) there is a solution: \[\begin{align}z &= g(x_1, y_1) \\ w &= h(x_1, y_1) \end{align} \] Then the joint density of \(\mathbf{z}\) and \(\mathbf{w}\) is <br> \(f_{\mathbf{z}\mathbf{w} } (z, w) = \) {{c1:: \( \frac{f_{\mathbf{x}\mathbf{y} } (x_1, y_1) } { | J(x_1, y_1) | } \) }} where {{c1:: \(| J(x_1, y_1) | \) }} is the {{c1::determinant}} of the {{c1::Jacobian}} of the transformation evaluated at {{c1:: \(x = x_1\)}} and {{c1:: \(y = y_1\) }}.; Section 6.3 slides number 16
SP_CH6_10; Marginal Statistics <br> \(F_{\mathbf{x} } (x) =\) {{c1::\(F_{\mathbf{x}, \mathbf{y} }(x, \infty) \) }}; Equation 6-9, pg 171
SP_CH6_11; Marginal Statistics <br> \(f_{\mathbf{x} } (x) =\) {{c1::\( \int_{-\infty}^{\infty} f_{\mathbf{x}, \mathbf{y} }(x, y) dy \) }}; Equation 6-10, pg 171
SP_CH6_12; {{c2::Conditional probability}} for joint densities <br> \(f(y|x) = \){{c1::\( \frac{f(x,y)} {f(x)} \)}}; Equation 6-205, pg 222
SP_CH6_13; {{c2::Bayes rule}} for joint densities <br> \(f(x|y) = \){{c1::\( \frac{f(y|x)f(x)} {f(y)} \)}}; Equation 6-212, pg 224
SP_CH6_14; {{c2::Bayes theorem}} for joint densities <br> \(f(x|y) = \){{c1::\( \frac{f(y|x)f(x)} {\int_{-\infty}^{\infty} f(y|x)f(x) dx } \)}}; Equation 6-214, pg 224
